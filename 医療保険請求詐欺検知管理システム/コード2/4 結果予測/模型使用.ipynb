{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2900b142-b75b-4745-80cf-89af5ddb826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings('ignore')    # 警告メッセージを無視"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bac377ec-b3cd-4ca0-9d52-297d2559033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 初期設定 (初始化设置) ==========\n",
    "\n",
    "# pandasですべての列を表示するように設定（省略なし）\n",
    "pd.set_option('display.max_columns', None) \n",
    "# 乱数シードを42に固定（再現性のため）\n",
    "np.random.seed(42) \n",
    "\n",
    "# 保存パスの設定読み込み\n",
    "DATA_PATH = '测试数据.xlsx'\n",
    "OUTPUT_PATH = '测试数据预处理结果.xlsx'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f862075c-20c7-4795-96fd-5ae6488bf2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据加载成功，原始形状：(9, 108)\n"
     ]
    }
   ],
   "source": [
    "# ========== データの読み込みと検証 (数据加载与校验) ==========\n",
    "\n",
    "# データ読み込み\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "# データ読み込み成功、元の形状を表示\n",
    "print(f\"数据加载成功，原始形状：{df.shape}\") #データの読み込みに成功、元の形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9271c4-2fd5-46c5-8bab-253ec708adb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已删除字段：['CLLI_OID', 'CL_NO', 'LINE_NO', 'BARCODE', 'FX_RATE', 'PRI_CORR_BRKR_NAME', 'SCMA_OID_BEN_TYPE', 'CRT_USER', 'UPD_USER', 'ID_CARD_NO', 'PHONE_NO', 'PAYEE_LAST_NAME', 'PAYEE_FIRST_NAME', 'CL_PAY_ACCT_NO', 'POCY_REF_NO', 'MBR_REF_NO', 'CLSH_HOSP_CODE', 'LINE_REMARK', 'CSR_REMARK', 'PLAN_REMARK', 'CL_LINE_FORMULA', 'CL_CLAIM_FORMULA', 'CL_INVOICE_FORMULA', 'KIND_CODE', 'MAN_REJ_CODE_DESC_1', 'MAN_REJ_CODE_DESC_2', 'BEN_HEAD_TYPE', 'MBR_REF_NO_B', 'ORG_INSUR_INVOICE_IND', 'MEPL_MBR_REF_NO_B', 'BANK_NAME', 'CL_PAY_ACCT_NAME', 'MAN_REJ_AMT_2', 'FILE_CLOSE_DATE', 'TOTAL_RECEIPT_AMT', 'MEPL_MBR_REF_NO', 'MAN_REJ_AMT_1', 'PROV_DEPT', 'MBR_LAST_NAME', 'FILE_ID', 'WORKPLACE_NAME', 'POCY_PLAN_DESC', 'INCUR_DATE_FROM', 'INCUR_DATE_TO', 'PAY_DATE', 'CRT_DATE', 'UPD_DATE', 'DIAG_DESC', 'SCMA_OID_CL_LINE_STATUS', 'RCV_DATE', 'MBR_FIRST_NAME', 'SCMA_OID_PROD_TYPE', 'SCMA_OID_CL_STATUS', 'SCMA_OID_CL_TYPE', 'SCMA_OID_COUNTRY_TREATMENT', 'MEMBER_EVENT', 'INSUR_INVOICE_IND', 'PROV_NAME', 'MBR_TYPE', 'BOX_BARCODE', 'PAY_AMT', 'STR_CRT_DATE', 'ORG_PRES_AMT', 'PROV_CODE', 'MBR_NO', 'STR_UPD_DATE', 'POHO_NO', 'POPL_OID', 'INVOICE_ID', 'CL_LINE_NO', 'PLAN_OID', 'POCY_NO', 'POLICY_CNT', 'INVOICE_NO', 'BEN_HEAD', 'RJ_CODE_LIST', 'RECHARGE_AMT']\n",
      "已删除全空列：['PAYMENT_STATUS', 'PAYMENT_AMENT_DATE', 'MAN_REJ_CODE_DESC_3', 'MAN_REJ_CODE_DESC_4', 'MAN_REJ_CODE_DESC_5', 'MAN_REJ_AMT_3', 'MAN_REJ_AMT_4', 'MAN_REJ_AMT_5', 'INVOICE_RTN_IND', 'AMT_DAY_USED', 'PAY_PCT_LIST']\n"
     ]
    }
   ],
   "source": [
    "# 不要な列の定義と削除\n",
    "# データクレンジングのプロセスでは、分析に不要な識別子や個人情報を削除します\n",
    "\n",
    "\n",
    "# CLLI_OID 一意識別子、特徴の汎化能力なし\n",
    "# CL_NO 請求番号、純粋な管理番号 \n",
    "# LINE_NO 請求明細行番号、分析価値なし\n",
    "# FX_RATE 為替レート（国内業務は1に固定）、実質的な意味なし  \n",
    "# SCMA_OID_BEN_TYPE BEN_TYPEと重複、冗長フィールド \n",
    "# BARCODE 個別案件コード、一意識別子\n",
    "# PRI_CORR_BRKR_NAME 固定値“BSI”、分析価値なし\n",
    "# CRT_USER 作成者、ユーザー行動とは無関係\n",
    "# UPD_USER 更新者、ユーザー行動とは無関係\n",
    "# ID_CARD_NO 身分証番号、プライバシーコンプライアンスリスクあり\n",
    "# PHONE_NO 電話番号、プライバシーコンプライアンスリスクあり\n",
    "# PAYEE_LAST_NAME 受取人姓、プライバシーコンプライアンスリスクあり \n",
    "# PAYEE_FIRST_NAME 受取人名、プライバシーコンプライアンスリスクあり\n",
    "# LINE_REMARK 非構造化テキスト、NLP処理が必要で利益は不確定                    \n",
    "# CSR_REMARK 非構造化テキスト、NLP処理が必要で利益は不確定                    \n",
    "# PLAN_REMARK 非構造化テキスト、NLP処理が必要で利益は不確定\n",
    "\n",
    "cols_to_drop = ['CLLI_OID', 'CL_NO', 'LINE_NO', 'BARCODE', 'FX_RATE','PRI_CORR_BRKR_NAME','SCMA_OID_BEN_TYPE', 'CRT_USER', 'UPD_USER',\n",
    "                'ID_CARD_NO', 'PHONE_NO', 'PAYEE_LAST_NAME', 'PAYEE_FIRST_NAME','CL_PAY_ACCT_NO','POCY_REF_NO','MBR_REF_NO','CLSH_HOSP_CODE',\n",
    "                'LINE_REMARK', 'CSR_REMARK', 'PLAN_REMARK','MAN_REJ_CODE_DESC_','CL_LINE_FORMULA','CL_CLAIM_FORMULA','CL_INVOICE_FORMULA',\n",
    "               'KIND_CODE','MAN_REJ_CODE_DESC_1','MAN_REJ_CODE_DESC_2','BEN_HEAD_TYPE','MBR_REF_NO_B','ORG_INSUR_INVOICE_IND','FILE_ID'\n",
    "               'MEPL_MBR_REF_NO','MEPL_MBR_REF_NO_B','MBR_LAST_NAME  ','BANK_NAME','CL_PAY_ACCT_NAME','FILE_ID ','MAN_REJ_AMT_2',\n",
    "               'FILE_CLOSE_DATE','TOTAL_RECEIPT_AMT','MEPL_MBR_REF_NO','MAN_REJ_AMT_1','PROV_DEPT','MBR_LAST_NAME','FILE_ID','WORKPLACE_NAME',\n",
    "                'POCY_PLAN_DESC','INCUR_DATE_FROM','INCUR_DATE_TO','PAY_DATE','CRT_DATE','UPD_DATE','DIAG_DESC','SCMA_OID_CL_LINE_STATUS',\n",
    "               'RCV_DATE','MBR_FIRST_NAME','SCMA_OID_PROD_TYPE','SCMA_OID_CL_STATUS','SCMA_OID_CL_TYPE','SCMA_OID_COUNTRY_TREATMENT','MEMBER_EVENT',\n",
    "               'INSUR_INVOICE_IND','PROV_NAME','MBR_TYPE','BOX_BARCODE','PAY_AMT','STR_CRT_DATE','ORG_PRES_AMT','PROV_CODE','MBR_NO','STR_UPD_DATE','POHO_NO',\n",
    "                'POPL_OID','INVOICE_ID','CL_LINE_NO','PLAN_OID','POCY_NO','POLICY_CNT','INVOICE_NO'\n",
    "               ,'BEN_HEAD','RJ_CODE_LIST','RECHARGE_AMT']\n",
    "# データフレームに存在する列のみを削除リストに保持\n",
    "cols_to_drop = [col for col in cols_to_drop if col in df.columns]\n",
    "df.drop(columns=cols_to_drop, inplace=True) #inplace=True表示直接在原DataFrame上修改\n",
    "print(f\"已删除字段：{cols_to_drop}\") #削除されたフィールド\n",
    "\n",
    "\n",
    "# 2. 目的変数のエンコーディング\n",
    "# 詐欺フラグの変換: 'AC' → 0（非詐欺/正常請求）, 'RJ' → 1（詐欺/拒絶/疑義）, 'PD'/'PV' → 1\n",
    "if 'CL_LINE_STATUS' in df.columns:\n",
    "    df['fraud'] = df['CL_LINE_STATUS'].map({'AC': 0, 'RJ': 1,'PD':1,'PV':1})\n",
    "    df.drop(columns=['CL_LINE_STATUS'], inplace=True)\n",
    "\n",
    "# すべてが空値の列を削除\n",
    "empty_cols = df.columns[df.isnull().all()].tolist()\n",
    "if empty_cols:\n",
    "    df.drop(empty_cols, axis=1, inplace=True)\n",
    "    print(f\"已删除全空列：{empty_cols}\") #すべて空のため削除された列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f28c2bb-762a-419d-bd57-4cf754fac8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-Max 标准化后的数据范围：\n",
      "     ORG_PRES_AMT_VALUE  APP_AMT  BEN_SPEND  PAY_AMT_USD  REJECTED_AMT  \\\n",
      "min                 0.0      0.0        0.0          0.0           0.0   \n",
      "max                 1.0      1.0        1.0          1.0           1.0   \n",
      "\n",
      "     SUB_AMT  CL_SOCIAL_PAY_AMT  CL_THIRD_PARTY_PAY_AMT  CL_OWNER_PAY_AMT  \\\n",
      "min      0.0                0.0                     0.0               0.0   \n",
      "max      1.0                1.0                     0.0               1.0   \n",
      "\n",
      "     CL_SELF_CAT_PAY_AMT  COPAY_PCT  CWF_AMT_DAY  DED_AMT  NO_OF_YR  \\\n",
      "min                  0.0        0.0          0.0      0.0       0.0   \n",
      "max                  1.0        1.0          0.0      0.0       0.0   \n",
      "\n",
      "     INVOICE_CNT  \n",
      "min          0.0  \n",
      "max          1.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 数値型列の選択（目的変数 'fraud' を除く）\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "num_cols = [col for col in num_cols if col != 'fraud']\n",
    "\n",
    "# MinMaxScalerの初期化（データを0から1の範囲に正規化）\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 選択された列に対してMin-Max正規化を実行\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "# 正規化後のデータ範囲を確認\n",
    "print(\"Min-Max 标准化后的数据范围：\") #Min-Max正規化後のデータ範囲\n",
    "print(df[num_cols].describe().loc[['min', 'max']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f876dd-d65a-42ed-b287-ab7594b60d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROV_LEVEL 编码映射关系：\n",
      "三级 → 0\n",
      "二级 → 1\n",
      "BEN_TYPE 的唯一值有 1 种，具体为：['OP']\n",
      "BEN_TYPE 编码映射关系：\n",
      "OP → 0\n",
      "DIAG_CODE 的前1个字符有 6 种，具体为：['K' 'G' 'L' 'E' 'M' 'R']\n",
      "DIAG_CODE 前1个字符编码映射关系：\n",
      "E → 0\n",
      "G → 1\n",
      "K → 2\n",
      "L → 3\n",
      "M → 4\n",
      "R → 5\n",
      "CODES 列已编码为字符串数量，新增列：CODES_COUNT\n"
     ]
    }
   ],
   "source": [
    "# 特徴量エンコーディング (カテゴリカル変数の数値化)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# PROV_LEVEL（プロバイダーレベル）のエンコーディング\n",
    "if 'PROV_LEVEL' in df.columns:\n",
    "    # LabelEncoderの初期化\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # エンコーディングの実行\n",
    "    df['PROV_LEVEL'] = label_encoder.fit_transform(df['PROV_LEVEL'])\n",
    "    \n",
    "    # エンコーディングのマッピング関係を出力\n",
    "    print(\"PROV_LEVEL 编码映射关系：\") #PROV_LEVEL エンコーディングマッピング関係\n",
    "    for i, label in enumerate(label_encoder.classes_):\n",
    "        print(f\"{label} → {i}\")\n",
    "\n",
    "\n",
    "\n",
    "# BEN_TYPE（給付タイプ）のエンコーディング\n",
    "if 'BEN_TYPE' in df.columns:\n",
    "    # 一意な値の統計\n",
    "    unique_ben_types = df['BEN_TYPE'].unique()\n",
    "    print(f\"BEN_TYPE 的唯一值有 {len(unique_ben_types)} 种，具体为：{unique_ben_types}\")\n",
    "    \n",
    "    # LabelEncoderの初期化と適用\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    \n",
    "    df['BEN_TYPE'] = label_encoder.fit_transform(df['BEN_TYPE'])\n",
    "    \n",
    "    # マッピング関係の出力\n",
    "    print(\"BEN_TYPE 编码映射关系：\")\n",
    "    for i, label in enumerate(label_encoder.classes_):\n",
    "        print(f\"{label} → {i}\")\n",
    "\n",
    "\n",
    "\n",
    "# DIAG_CODE（診断コード）のエンコーディング（最初の1文字に基づく）\n",
    "if 'DIAG_CODE' in df.columns:\n",
    "    # 分類基準として最初の1文字を抽出\n",
    "    df['DIAG_CODE_PREFIX'] = df['DIAG_CODE'].str[:1]\n",
    "    \n",
    "    # プレフィックスの一意な値を確認\n",
    "    unique_prefixes = df['DIAG_CODE_PREFIX'].unique()\n",
    "    print(f\"DIAG_CODE 的前1个字符有 {len(unique_prefixes)} 种，具体为：{unique_prefixes}\")\n",
    "    \n",
    "    # LabelEncoderの初期化と適用\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['DIAG_CODE_PREFIX'] = label_encoder.fit_transform(df['DIAG_CODE_PREFIX'])\n",
    "    \n",
    "    # マッピング関係の出力\n",
    "    print(\"DIAG_CODE 前1个字符编码映射关系：\")\n",
    "    for i, label in enumerate(label_encoder.classes_):\n",
    "        print(f\"{label} → {i}\")\n",
    "    \n",
    "    # マッピング関係の出力\n",
    "    df.drop(columns=['DIAG_CODE'], inplace=True)\n",
    "\n",
    "\n",
    "# 1. CODES列の存在確認\n",
    "if 'CODES' in df.columns:\n",
    "    # 2. 欠損値を埋めて文字列型に変換\n",
    "    df['CODES'] = df['CODES'].fillna('').astype(str)\n",
    "    \n",
    "    # 3. カンマ区切りの項目数をカウントして新しい特徴量とする\n",
    "    df['CODES_COUNT'] = df['CODES'].apply(lambda x: len(x.split(',')) if x else 0)\n",
    "    \n",
    "    # 4. 元のCODES列を削除\n",
    "    df.drop(columns=['CODES'], inplace=True)\n",
    "    \n",
    "    print(\"CODES 列已编码为字符串数量，新增列：CODES_COUNT\")\n",
    "    #CODES列は項目数にエンコードされました、追加列：CODES_COUNT\n",
    "else:\n",
    "    print(\"数据中未找到 CODES 列，请检查数据！\")\n",
    "    #データ内にCODES列が見つかりません。データを確認してください！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f175483-2d93-4ae5-a8ad-13dbb2f766af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "数据处理完成，结果已保存到: C:\\Users\\27826\\Desktop\\项目\\4.结果预测\\测试数据预处理结果.xlsx\n",
      "最终数据形状：(9, 20)\n"
     ]
    }
   ],
   "source": [
    "# ========== データ出力 (数据输出) ==========\n",
    "\n",
    "# 出力ディレクトリが存在することを確認\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH) or '.', exist_ok=True)\n",
    "\n",
    "# 処理後のデータをExcelファイルとして保存\n",
    "df.to_excel(OUTPUT_PATH, index=False)\n",
    "print(f\"\\n数据处理完成，结果已保存到: {os.path.abspath(OUTPUT_PATH)}\")\n",
    "#データ処理完了、結果保存先\n",
    "print(f\"最终数据形状：{df.shape}\")\n",
    "#最終データ形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed6e1804-d24c-40aa-958d-08bca6516026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: xgboost in c:\\programdata\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: openpyxl in c:\\programdata\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\programdata\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas xgboost joblib openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cbdec25-7338-4350-9232-0124f2eb5cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a3b1822-40fa-49c8-9844-afbb15739151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 20)\n"
     ]
    }
   ],
   "source": [
    "# 前処理済みのデータを読み込む\n",
    "df = pd.read_excel('测试数据预处理结果.xlsx')\n",
    "\n",
    "# データの形状を確認\n",
    "print(df.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39bb7ca4-fc49-40b4-955e-f7eca44bdf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理后的特征： ['PROV_LEVEL', 'INVOICE_CNT', 'CL_THIRD_PARTY_PAY_AMT', 'CWF_AMT_DAY', 'CODES_COUNT', 'CL_OWNER_PAY_AMT', 'PAY_AMT_USD', 'APP_AMT', 'BEN_SPEND', 'DIAG_CODE_PREFIX', 'BEN_TYPE', 'DED_AMT']\n"
     ]
    }
   ],
   "source": [
    "# ========== 特徴量の動的調整 (动态调整特征) ==========\n",
    "\n",
    "# モデルの学習時に使用された特徴量リスト\n",
    "expected_columns = ['PROV_LEVEL', 'INVOICE_CNT', 'CL_THIRD_PARTY_PAY_AMT', 'CWF_AMT_DAY', 'CODES_COUNT', \n",
    "                    'CL_OWNER_PAY_AMT', 'PAY_AMT_USD', 'APP_AMT', 'BEN_SPEND', 'DIAG_CODE_PREFIX', 'BEN_TYPE', 'DED_AMT']\n",
    "\n",
    "# 1. 余分な特徴量を削除\n",
    "# モデルが使用する特徴量のみを保持する\n",
    "df = df[[col for col in expected_columns if col in df.columns]]\n",
    "\n",
    "# 2. 不足している特徴量を追加\n",
    "# 現在のデータにモデル学習時にあった特徴量が欠けている場合、デフォルト値（0）で埋める\n",
    "for col in expected_columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = 0  # デフォルト値0で埋める\n",
    "\n",
    "# 3. 特徴量の順序をモデル学習時と一致させる（非常に重要）\n",
    "df = df[expected_columns]\n",
    "\n",
    "# 処理後の特徴量リストを出力\n",
    "print(\"处理后的特征：\", df.columns.tolist()) #処理後の特徴量リスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3b2b2ce-e23d-448f-9326-e0dfb303134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存されたモデルをロード\n",
    "model = joblib.load('best_xgboost_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91b60952-8fc9-406f-ae79-be86e44f2ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# 予測を実行\n",
    "predictions = model.predict(df)\n",
    "\n",
    "# 予測結果を出力\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27f55ec9-0122-48e7-9a4c-233ef7d2815f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROV_LEVEL</th>\n",
       "      <th>INVOICE_CNT</th>\n",
       "      <th>CL_THIRD_PARTY_PAY_AMT</th>\n",
       "      <th>CWF_AMT_DAY</th>\n",
       "      <th>CODES_COUNT</th>\n",
       "      <th>CL_OWNER_PAY_AMT</th>\n",
       "      <th>PAY_AMT_USD</th>\n",
       "      <th>APP_AMT</th>\n",
       "      <th>BEN_SPEND</th>\n",
       "      <th>DIAG_CODE_PREFIX</th>\n",
       "      <th>BEN_TYPE</th>\n",
       "      <th>DED_AMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.875</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>-0.287884</td>\n",
       "      <td>-0.287884</td>\n",
       "      <td>-0.287884</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PROV_LEVEL  INVOICE_CNT  CL_THIRD_PARTY_PAY_AMT  CWF_AMT_DAY  \\\n",
       "mean      -0.875       -0.625                     0.0          0.0   \n",
       "std          NaN          NaN                     NaN          NaN   \n",
       "\n",
       "      CODES_COUNT  CL_OWNER_PAY_AMT  PAY_AMT_USD   APP_AMT  BEN_SPEND  \\\n",
       "mean        0.875          0.678571    -0.287884 -0.287884  -0.287884   \n",
       "std           NaN               NaN          NaN       NaN        NaN   \n",
       "\n",
       "      DIAG_CODE_PREFIX  BEN_TYPE  DED_AMT  \n",
       "mean              0.25       0.0      0.0  \n",
       "std                NaN       NaN      NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 予測結果の分析\n",
    "# モデルが「詐欺」と判定したサンプルを抽出し、その特徴を分析します\n",
    "# 負例（詐欺と予測されたサンプル、値が1）を取得\n",
    "negative_samples = df[predictions == 1]\n",
    "\n",
    "# 負例の特徴分布統計を表示\n",
    "negative_samples.describe()\n",
    "\n",
    "# 負例（詐欺）と正例（正常）の特徴分布の比較\n",
    "# 平均値(mean)と標準偏差(std)の差分を計算して、どのような傾向の違いがあるか確認\n",
    "positive_samples = df[predictions == 0]\n",
    "negative_samples.describe().loc[['mean', 'std']] - positive_samples.describe().loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc598f06-0b13-4b8e-8d58-ddd17b049109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud                     1.000000\n",
      "CODES_COUNT               0.661438\n",
      "CL_OWNER_PAY_AMT          0.553111\n",
      "DIAG_CODE_PREFIX          0.053300\n",
      "PAY_AMT_USD              -0.317201\n",
      "APP_AMT                  -0.317201\n",
      "BEN_SPEND                -0.317201\n",
      "INVOICE_CNT              -0.395285\n",
      "PROV_LEVEL               -0.661438\n",
      "CL_THIRD_PARTY_PAY_AMT         NaN\n",
      "CWF_AMT_DAY                    NaN\n",
      "BEN_TYPE                       NaN\n",
      "DED_AMT                        NaN\n",
      "Name: fraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 予測結果をDataFrameに追加\n",
    "df['fraud'] = predictions\n",
    "\n",
    "# 特徴量と目的変数（予測されたfraud）との相関関係を計算\n",
    "correlation = df.corr()['fraud'].sort_values(ascending=False)\n",
    "\n",
    "# 相関係数を出力\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6f9f4ab-83bf-4aef-9159-5adf3cbb4e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征 PROV_LEVEL: 重要性 = 0.010\n",
      "特征 INVOICE_CNT: 重要性 = 0.008\n",
      "特征 CL_THIRD_PARTY_PAY_AMT: 重要性 = 0.015\n",
      "特征 CWF_AMT_DAY: 重要性 = 0.018\n",
      "特征 CODES_COUNT: 重要性 = 0.025\n",
      "特征 CL_OWNER_PAY_AMT: 重要性 = 0.017\n",
      "特征 PAY_AMT_USD: 重要性 = 0.211\n",
      "特征 APP_AMT: 重要性 = 0.477\n",
      "特征 BEN_SPEND: 重要性 = 0.189\n",
      "特征 DIAG_CODE_PREFIX: 重要性 = 0.005\n",
      "特征 BEN_TYPE: 重要性 = 0.010\n",
      "特征 DED_AMT: 重要性 = 0.014\n"
     ]
    }
   ],
   "source": [
    "# 特徴量の重要度を取得（Feature Importance）\n",
    "# モデルが予測を行う際に、どの特徴量を重視したかを確認します\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# 各特徴量の重要度を出力\n",
    "for i, importance in enumerate(importances):\n",
    "    print(f\"特征 {df.columns[i]}: 重要性 = {importance:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b46296-46c6-42a8-ac09-49a9e3994365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
