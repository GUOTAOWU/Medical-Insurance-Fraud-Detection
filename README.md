# AIを活用した医療保険請求詐欺検知管理システム
# (AI-Powered Medical Insurance Fraud Detection Management System)

## 1. プロジェクトの概要 (Introduction)
本プロジェクトは、Python (Flask) をベースに構築されたWebアプリケーションであり、機械学習を活用して医療保険請求データにおける「正常」な請求と「不正（詐欺）」の疑いがある請求を自動的に識別・監査するシステムです。

膨大な医療保険請求データの中から、AIが不正請求のパターンを検知することで、監査担当者の業務負担を軽減し、審査プロセスの効率化と精度の向上を目的としています。データの取り込みからAIによる分析、そして最終的な審査管理までをワンストップで行える統合業務システムです。

## 2. ディレクトリ構造とファイル説明 (File Description)


本プロジェクトは、大きく分けて「システム実装用（コード1）」と「データ分析・モデル開発プロセス用（コード2）」の2つのディレクトリで構成されています。

### 📂 プロジェクト構成図

```text
Project_Root
│
├── 📂 コード1/code  (Webアプリケーション実装 - System Deployment)
│   │  本番環境で稼働するFlaskシステムのコード一式です。
│   │
│   ├── 📂 templates/             # フロントエンド画面のHTMLテンプレート
│   ├── 📄 app.db                 # SQLiteデータベース（ユーザー情報や監査ログの保存）
│   ├── 📄 app.py                 # メインアプリケーションコード（Flask起動、ルーティング）
│   ├── 📄 best_xgboost_model.pkl # 学習済みAIモデル（システムが予測に使用するもの）
│   ├── 📄 test.xlsx              # システム動作確認用のテストデータ（多量）
│   └── 📄 test1.xlsx             # システム動作確認用のテストデータ（少量）
│
└── 📂 コード2 (データサイエンス・開発プロセス - Development Workflow)
    │  モデル完成に至るまでの前処理、学習、実験の過程が含まれています。
    │
    ├── 📂 1 データ
    │      # プロジェクトの初期データ保存場所
    │
    ├── 📂 2 データ前処理、特徴量エンジニアリング (Preprocessing)
    │      ├── 📄 data-14-01.xlsx      # 初期（Raw）データ
    │      ├── 📄 processed_data.xlsx  # 一次クリーニング後のデータ
    │      ├── 📄 最終データ.xlsx         # 前処理完了後の最終データ（学習に使用）
    │      └── 📓 データ.ipynb            # 前処理ロジックを記述したJupyter Notebook
    │
    ├── 📂 3 機械学習 (Model Training)
    │      ├── 📓 model.ipynb          # モデル学習・比較・評価のコード
    │      ├── 📄 最終データ.xlsx         # 学習に使用したデータセット
    │      ├── 📄 best_xgboost_model.pkl      # 【採用】最高精度のXGBoostモデル
    │      ├── 📄 optimized_xgboost_model.pkl # チューニング済みXGBoostモデル
    │      ├── 📄 best_traditional_model.pkl  # 比較用モデル（RandomForest等）
    │      └── 📄 mlp_model.pkl               # 比較用モデル（多層パーセプトロン）
    │
    └── 📂 4 結果予測 (Prediction & Validation)
           ├── 📓 モデル推論.ipynb            # 学習済みモデルを使用した予測テストのコード
           ├── 📄 テストデータ.xlsx             # テスト用生データ
           ├── 📄 前処理済みテストデータ.xlsx     # テストデータを前処理した結果
           └── 📄 best_xgboost_model.pkl    # 予測に使用するモデルファイル

## 3. データセット (Dataset)
本システムは、医療保険請求の詳細情報が含まれた **Excel形式 (.xlsx)** のデータを使用します。
データには、請求金額、医療機関情報、診断コード、患者情報などの属性が含まれており、これらをAIモデルの学習および予測の入力データとして利用します。

## 4. 使用手法・アルゴリズム (Methodology)
本システムでは、以下のデータサイエンスおよび機械学習の手法を採用しています。

### A. データ前処理 (Data Preprocessing)
* **クレンジング:** Excelデータの読み込み、欠損値の処理、不要な列の削除。
* **正規化:** 数値データのMin-Max Scaling。
* **エンコーディング:** カテゴリカルデータの数値化。

### B. 不均衡データの処理 (Handling Imbalanced Data)
詐欺データは正常データに比べて極端に少ないため、**SMOTE + Tomek Links** 法を用いてデータのバランスを調整し、モデルが詐欺パターンを適切に学習できるよう最適化しています。

### C. 機械学習モデル (Machine Learning Models)
以下のアルゴリズムを用いてモデルを訓練し、請求が「0: 正常」か「1: 詐欺」かを分類します。
* **XGBoost** (メインモデル)
* Random Forest (比較用など)
* MLP
* SVM

また、**特徴量分析**を行い、どの項目（金額や診断コードなど）が詐欺判定に強く寄与したかを可視化します。

## 5. 実施プロセスと機能 (Implementation & Workflow)
本システムはWebアプリケーションとして実装されており、以下の流れで業務を行います。

### 技術スタック
* **Backend:** Python, Flask, SQLAlchemy
* **Frontend:** HTML, Bootstrap 5
* **AI/Analysis:** Pandas, Scikit-learn, XGBoost, Imbalanced-learn
* **Database:** SQLite (開発環境)

### 具体的な業務フロー
1.  **ログイン (Login):**
    * 管理者がセキュアな環境（パスワードハッシュ化、CAPTCHA認証）でログインします。
2.  **データ入力 (Data Import):**
    * 新しい保険請求データをExcelファイルで一括インポートします。
    * システム内でデータのCRUD操作（作成・参照・更新・削除）も可能です。
3.  **AI監査実行 (AI Audit):**
    * 監査ページにて対象データを選択し、予測を実行します。
4.  **結果確認 (Result Verification):**
    * AIが「詐欺疑い」と判定した案件がカード形式で表示されます。
    * 詐欺グループと正常グループの統計的差異や、判定根拠を確認します。
5.  **対応・ステータス更新 (Action):**
    * 担当者が最終判断を行い、システム上でステータス（承認/拒絶）を更新します。

## 6. 結論 (Conclusion)
本システムの実装により、従来の手作業による監査に比べ、不正請求の発見率向上と審査時間の短縮が期待できます。不均衡データへの適切な対処とXGBoostなどの高性能モデルの組み合わせにより、高精度な予測を実現しました。単なる予測モデルに留まらず、実業務で運用可能な管理画面を備えた包括的なソリューションとなっています。

## 7. 詳細プロセス (Process Description)

本プロジェクトでは、高精度な予測を実現するために以下の厳密なデータ処理パイプラインを構築しました。

### 7.1 データ前処理と特徴量エンジニアリング (Data Preprocessing)
`コード2/2 データ前処理.../データ.ipynb` において、以下の手順で生データを学習用データに変換しました。

1.  **データクレンジング:**
    * 個人情報（氏名、電話番号、ID）や分析に不要な管理ID（請求番号など）を含む列を削除しました。
    * **目的変数の作成:** `CL_LINE_STATUS` 列をマッピングし、`AC`を「0:正常」、`RJ/PD/PV`を「1:詐欺（不正）」として二値分類ラベル `fraud` を生成しました。
2.  **欠損値・外れ値の処理:**
    * **欠損値:** 数値列は「中央値」、カテゴリ列は「最頻値」で補完しました。
    * **外れ値:** 3σ法（平均 ± 3×標準偏差）を適用し、極端な値を境界値に置き換えました。
3.  **特徴量エンジニアリング:**
    * **正規化:** `MinMaxScaler` を使用し、すべての数値データを 0～1 の範囲にスケーリングしました。
    * **エンコーディング:** `PROV_LEVEL`, `BEN_TYPE` を数値化し、`DIAG_CODE`（診断コード）は先頭1文字を抽出してカテゴリ化しました。また、`CODES` 列はカンマ区切りの要素数（`CODES_COUNT`）に変換しました。
4.  **特徴量選択 (Feature Selection):**
    * カイ二乗検定（Chi-Squared Test）を実施し、p値 < 0.05 の統計的に有意な特徴量のみを抽出しました。
    * ランダムフォレストによる重要度分析と相関ヒートマップで有効性を確認し、最終的に `最終データ.xlsx` として保存しました。

### 7.2 機械学習モデルの構築と最適化 (Model Training & Optimization)
`コード2/3 機械学習/model.ipynb` では、不均衡データへの対処と、最適なアルゴリズムの選定を行いました。

1.  **不均衡データへの対処 (Handling Imbalance):**
    * 正常データと詐欺データの比率が偏っているため、**SMOTE + Tomek Links** の複合サンプリング手法を採用しました。
    * これにより、少数派（詐欺）クラスを合成生成(SMOTE)しつつ、境界付近のノイズデータを除去(Tomek)し、モデルが詐欺パターンを学習しやすい分布に調整しました。

2.  **モデル選定と競合評価 (Model Selection):**
    * 以下のアルゴリズムに対し、クロスバリデーション（5-fold CV）を用いて性能を比較しました。
        * **Random Forest:** バランスの取れたベースラインモデル。
        * **SVM (Support Vector Machine):** 線形分離可能性の検証。
        * **MLP (Multi-Layer Perceptron):** ニューラルネットワークによる非線形パターンの学習。
        * **XGBoost:** 高い勾配ブースティング性能。
    * 評価指標には、不均衡データにおいて正解率(Accuracy)よりも重要な **F1-score (Macro)** を採用しました。比較の結果、XGBoostが最も安定して高い性能を示しました。

3.  **ハイパーパラメータチューニング (Hyperparameter Tuning):**
    * **検証曲線 (Validation Curve):** `n_estimators`, `max_depth`, `learning_rate` などの主要パラメータがモデル性能に与える影響を可視化し、過学習（Overfitting）と学習不足（Underfitting）のバランスを確認しました。
    * **グリッドサーチ (Grid Search):** 段階的にパラメータ空間を探索し、正則化パラメータ（`gamma`, `reg_alpha`）を含む最適な組み合わせを特定しました。
    * 最終的に最適化されたモデルを `best_xgboost_model.pkl` として保存し、システム実装に使用しました。

### 7.3 予測と結果の検証 (Prediction & Validation)
学習済みモデルを未知のデータに適用するプロセスは `コード2/4 結果予測/モデル推論.ipynb` に記述されています。

1.  **テストデータの前処理と特徴量の整合性確保:**
    * テストデータに対しても学習時と同様のクレンジング（欠損値処理、正規化）を行います。
    * **特徴量の動的調整:** 学習済みモデルが期待する入力形式（`expected_columns`）に合わせるため、テストデータに不足している列は補完し、余分な列は削除する処理を実装しました。これにより、モデル入力時の次元不一致エラーを防ぎます。

2.  **推論実行 (Inference):**
    * 保存された `best_xgboost_model.pkl` をロードし、整形済みのテストデータに対して予測を実行します。

3.  **結果の分析と解釈 (Result Analysis):**
    * **統計的差異の検証:** 予測結果に基づきデータを「正常グループ」と「詐欺グループ」に分割し、各特徴量の平均値や標準偏差を比較しました。これにより、詐欺と判定された案件が統計的にどのような傾向（例：特定の請求金額が高い、特定の診断コードが多い等）を持つかを可視化しました。
    * **重要度確認:** 推論時にモデルがどの特徴量を重視したかを再確認し、判定ロジックの透明性を確保しました。

